{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Experiment_7.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyPgEUqi02J6KdOwxD/zkBQg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"VGYJOjribEnT"},"source":["from google.colab import drive\n","%load_ext tensorboard\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5H8aZ1abKH3"},"source":["!python3 '/content/drive/My Drive/human_motion/main.py' --num_lstm 2 --latent_size 10 --lstm_hidden_size 100 --batch_size 4 --unbalancing_rate 0.5 --mode 'lstm' \\\n","--train_continue 'off' \\\n","--lstm_ckpt_dir '/content/drive/My Drive/human_motion/ex_classification/experiment_2/checkpoint' \\\n","--lstm_log_dir '/content/drive/My Drive/human_motion/ex_classification/experiment_2/log' \\\n","--oversampling_ckpt_dir '/content/drive/My Drive/human_motion/ex_oversampling/experiment_2/checkpoint' \\\n","--oversampling_log_dir '/content/drive/My Drive/human_motion/ex_oversampling/experiment_2/log' \\\n","--weight_balancing_ckpt_dir '/content/drive/My Drive/human_motion/ex_weight_balancing/experiment_2/checkpoint' \\\n","--weight_balancing_log_dir '/content/drive/My Drive/human_motion/ex_weight_balancing/experiment_2/log' \\\n","--feature_gan_ckpt_dir '/content/drive/My Drive/human_motion/ex_feature_gan/experiment_2/checkpoint' \\\n","--feature_gan_log_dir '/content/drive/My Drive/human_motion/ex_feature_gan/experiment_2/log' \\\n","--lstm_retrain_ckpt_dir '/content/drive/My Drive/human_motion/ex_lstm_retrain/experiment_2/checkpoint' \\\n","--lstm_retrain_log_dir '/content/drive/My Drive/human_motion/ex_lstm_retrain/experiment_2/log'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vPSvgnhkXnsW"},"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","\n","\n","def CB_loss(labels, logits, samples_per_cls, no_of_classes, loss_type, beta, gamma):\n","    \"\"\"Compute the Class Balanced Loss between `logits` and the ground truth `labels`.\n","    Class Balanced Loss: ((1-beta)/(1-beta^n))*Loss(labels, logits)\n","    where Loss is one of the standard losses used for Neural Networks.\n","    Args:\n","      labels: A int tensor of size [batch].\n","      logits: A float tensor of size [batch, no_of_classes].\n","      samples_per_cls: A python list of size [no_of_classes].\n","      no_of_classes: total number of classes. int\n","      loss_type: string. One of \"sigmoid\", \"focal\", \"softmax\".\n","      beta: float. Hyperparameter for Class balanced loss.\n","      gamma: float. Hyperparameter for Focal loss.\n","    Returns:\n","      cb_loss: A float tensor representing class balanced loss\n","    \"\"\"\n","    effective_num = 1.0 - np.power(beta, samples_per_cls)\n","    weights = (1.0 - beta) / np.array(effective_num)\n","    weights = weights / np.sum(weights) * no_of_classes\n","\n","    labels_one_hot = F.one_hot(labels, no_of_classes).float()\n","\n","    weights = torch.tensor(weights).float()\n","    weights = weights.unsqueeze(0)\n","    weights = weights.repeat(labels_one_hot.shape[0],1) * labels_one_hot\n","    weights = weights.sum(1)\n","    weights = weights.unsqueeze(1)\n","    weights = weights.repeat(1,no_of_classes)\n","\n","    if loss_type == \"focal\":\n","        cb_loss = focal_loss(labels_one_hot, logits, weights, gamma)\n","    elif loss_type == \"sigmoid\":\n","        cb_loss = F.binary_cross_entropy_with_logits(input = logits,target = labels_one_hot, weights = weights)\n","    elif loss_type == \"softmax\":\n","        pred = logits.softmax(dim = 1)\n","        cb_loss = F.binary_cross_entropy(input = pred, target = labels_one_hot, weight = weights)\n","    return cb_loss\n","\n","\n","\n","if __name__ == '__main__':\n","    no_of_classes = 5\n","    logits = torch.rand(10,no_of_classes).float()\n","    print(logits)\n","    labels = torch.randint(0,no_of_classes, size = (10,))\n","    print(labels)\n","    beta = 0.9999\n","    gamma = 2.0\n","    samples_per_cls = [2,3,1,2,2]\n","    loss_type = \"focal\"\n","    cb_loss = CB_loss(labels, logits, samples_per_cls, no_of_classes,loss_type, beta, gamma)\n","    print(cb_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oyD4EEofsuhL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZkw3XdouYeY"},"source":["print('='*40)\n","print('The entered \"mode\" does not exist')\n","print('='*40)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaGRAfs1lP7Y"},"source":["sample_per_cls = [1]*12\n","for i in range(12):\n","    if i % 2 ==0:\n","        sample_per_cls[i] *= 0.5\n","\n","print(sample_per_cls)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmJGvGyzrXB1"},"source":["from torch.autograd import Variable\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","\n","batch_size = 4\n","latent_dim = 10\n","n_classes = 12\n","\n","label_emb = nn.Embedding(n_classes, latent_dim)\n","\n","z = Variable(torch.FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n","gen_labels = Variable(torch.LongTensor(np.random.randint(0, n_classes, batch_size)))\n","\n","print(z)\n","print(gen_labels)\n","\n","print(label_emb(gen_labels))\n","z.mul_(label_emb(gen_labels))\n","print(z)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDyXJVEh1yjQ"},"source":[""],"execution_count":null,"outputs":[]}]}