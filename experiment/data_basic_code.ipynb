{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_basic_code.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1COxk-oEA8brONaLFNRwAp3g3fZOR3cK4","authorship_tag":"ABX9TyNa88LF6GL37pj/R506kbLc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"D2NrJn0jlXcE"},"source":[""]},{"cell_type":"code","metadata":{"id":"5VwbzStplW6d"},"source":["\n","!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","from google.colab import drive\n","from torch.utils.tensorboard import SummaryWriter\n","import os\n","import numpy as np\n","import glob\n","import torchvision\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import matplotlib.pyplot as plt\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import torch.functional as F\n","import torch.autograd as autograd\n","drive.mount('/content/drive', force_remount=True)\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iEkPulO6beq8"},"source":["dataset 전처리 및 로드 코드"]},{"cell_type":"code","metadata":{"id":"rcf_2sICbnLh"},"source":["class data_load(Dataset):\n","\n","    def __init__(self, input_path):\n","        self.data_file_list = getFileNames(input_path)\n","        # \n","\n","    def __len__(self):\n","        return len(self.data_file_list)\n","\n","    def __getitem__(self, index):\n","        self.data = readDataFile(self.data_file_list[index])\n","        self.label = parseFileName(self.data_file_list[index])\n","        return self.data, self.label\n","\n","def getFileNames(input_path):\n","    input_path = glob.glob('%s/*.csv' % input_path)\n","\n","    csv_list = []\n","    for i in range(len(input_path)):\n","        contents = np.genfromtxt(input_path[i], delimiter=' ')\n","        data = list(contents[20:,1:])\n","        if len(data) <= 2000:\n","            csv_list.append(input_path[i])\n","\n","    return csv_list\n","\n","def parseFileName(fName):\n","    # gestureId_list = []\n","\n","    # for fName in dataFile:\n","    fName = fName.split(\"/\")[-1]\n","    noSuffix = fName.split(\".\")[0]\n","    fields = noSuffix.split(\"_\")\t\n","    gestureId = fields[2]\t\t\t\t\n","    if (gestureId[-1] == 'A'):\n","        twoModalities = True\n","        gestureId = gestureId[:-1]\n","\n","    # gestureId_list.append(int(gestureId)-1)\n","    # gestureId_list = np.array(gestureId_list)\n","    return torch.tensor(int(gestureId)-1)\n","\n","def readDataFile(dataFile):\n","    # data_all = []\n","    \n","    # for m in range(len(dataFile)):\n","    contents = np.genfromtxt(dataFile, delimiter=' ')\n","    data = list(contents[20:,1:])\n","\n","    data_list = []\n","\n","    for i in range(len(data)):\n","        data_line = []\n","        \n","        if data[i][0] == 0 and data[i][1] == 0 and data[i][2] == 0:\n","            continue \n","        while len(data[i]) != 0:\n","            for _ in range(3):\n","                data_line.append(data[i][0])\n","                data[i] = np.delete(data[i],0)\n","            data[i] = np.delete(data[i],0)\n","        data_list.append(data_line)\n","\n","        # data_all.append(torch.tensor(data_list))\n","    \n","    # data_all = torch.nn.utils.rnn.pad_sequence(data_all)\n","    # print(data_all.size())\n","    # pad = [0]*3\n","    \n","    # for i in range(len(data_list)):\n","    #     if len(data_list) < 2000:\n","    #         for _ in range(2000-len(data_list)):\n","    #             data_list.append(pad)\n","    # if len(data_list) != 2000:\n","    #     print(dataFile)\n","    # data_list = np.array(data_list)\n","\n","    index = []\n","    A = len(data_list) // 100\n","    for i in range(0,len(data_list),A):\n","        if len(index) == 100:\n","            break\n","        index.append(data_list[i])\n","    data_list = index\n","    return torch.tensor(data_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-4BiQtEpcM7o"},"source":["사용 model 코드"]},{"cell_type":"code","metadata":{"id":"oWASfHfqb9ki"},"source":["class RNN_MODEL(nn.Module):\n","    def __init__(self, input_size, hidden_size, batch_size, sequence_length, num_layers, num_classes, device):\n","        super(RNN_MODEL, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=0.2, batch_first=True)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.hidden_size,num_classes)\n","        )\n","        self.device = device\n","    \n","    def forward(self, x):\n","        # Set initial hidden and cell states\n","        \n","       \n","        # packed_input = torch.nn.utils.rnn.pack_padded_sequence(x, input_lengths.tolist(), batch_first=True)\n","\n","\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n","        # Forward propagate LSTM\n","\n","        out, (ht, ct) = self.lstm(x, (h0, c0))\n","          # out: tensor of shape (batch_size, seq_length, hidden_size)\n","        # Decode the hidden state of the last time step\n","        # out = out.contiguous().view(len(out), sequence_length*hidden_size)\n","        \n","        out = self.classifier(ht[-1])\n","        \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9T0ON1Adkf9"},"source":["hyperparameter 조정"]},{"cell_type":"code","metadata":{"id":"2PWDESREdnbJ"},"source":["# Hyper-parameters\n","sequence_length = 2000\n","input_size = 60\n","hidden_size = 30\n","num_layers = 1\n","num_classes = 12\n","batch_size = 1\n","num_epochs = 20\n","learning_rate = 0.01\n","device = torch.device('cuda')\n","train_path = '/content/drive/My Drive/human_motion/traindata'\n","test_path = '/content/drive/My Drive/human_motion/testdata'\n","net = RNN_MODEL(input_size, hidden_size, batch_size, sequence_length, num_layers, num_classes, device)\n","net.to(device)\n","#net.load_state_dict(torch.load('/content/drive/My Drive/human_motion/model/test_acc_0.8608695652173913.pt'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFChUBCj5btx"},"source":["dataset load 코드"]},{"cell_type":"code","metadata":{"id":"5rs0tJ5k5cb0"},"source":["train_dataset = data_load(train_path)\n","test_dataset = data_load(test_path)\n","train_loader = DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vc4TtJKFcb0T"},"source":["main 코드"]},{"cell_type":"code","metadata":{"id":"KYBorU-bca2O"},"source":["criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","total_step = len(train_loader)\n","\n","max_test_acc = 0.7217\n","for epoch in range(num_epochs):\n","    net.train()\n","    train_correct = 0\n","    train_total = 0\n","    loss_arr = []\n","    acc_arr = []\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device,dtype=torch.float32)\n","        labels = labels.to(device)\n","        # labels = labels.reshape(batch_size,1)\n","        # Forward pass\n","        print(torch.cuda.is_available())\n","        if i%5 == 0 :\n","            !nvidia-smi\n","        outputs = net(images)\n","        loss = criterion(outputs, labels)\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        loss_arr+=[loss.item()]\n","        _, predicted = torch.max(outputs.data, 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    \n","    train_accuracy = train_correct/train_total\n","    # Test the net\n","    net.eval()\n","    with torch.no_grad():\n","        test_correct = 0\n","        test_total = 0\n","        for images, labels in test_loader:\n","            images = images.to(device,dtype=torch.float32)\n","            labels = labels.to(device)\n","            outputs = net(images)\n","            test_loss = criterion(outputs,labels)\n","            _, predicted = torch.max(outputs.data, 1)\n","            test_total += labels.size(0)\n","            test_correct += (predicted == labels).sum().item()\n","        test_accuracy = test_correct/test_total\n","    \n","    if test_accuracy > max_test_acc:\n","        max_test_acc = test_accuracy\n","        torch.save(net.state_dict(), '/content/drive/My Drive/human_motion/model/test_acc_{}.pt'.format(max_test_acc))\n","        \n","    print('Epoch [{}/{}] \\t train_Loss: {:.4f}, train_Accuracy: {:.4f} \\t test_Loss: {:.4f}, test_Accuracy: {:.4f}' .format(epoch+1, num_epochs, loss.item(), train_accuracy ,test_loss.item(), test_accuracy))\n","     \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CSAd5tfsMh5Z"},"source":["Epoch [1/20], Step [114/114], Loss: 2.5605\n","Epoch [2/20], Step [114/114], Loss: 2.7035\n","Epoch [3/20], Step [114/114], Loss: 2.2247\n","Epoch [4/20], Step [114/114], Loss: 1.9691\n","Epoch [5/20], Step [114/114], Loss: 2.1249\n","Epoch [6/20], Step [114/114], Loss: 2.2739\n","Epoch [7/20], Step [114/114], Loss: 2.2131\n","Epoch [8/20], Step [114/114], Loss: 2.4138\n","Epoch [9/20], Step [114/114], Loss: 1.9373\n","Epoch [10/20], Step [114/114], Loss: 2.0335\n","Epoch [11/20], Step [114/114], Loss: 1.7445\n","Epoch [12/20], Step [114/114], Loss: 1.8453\n","Epoch [13/20], Step [114/114], Loss: 1.5977\n","Epoch [14/20], Step [114/114], Loss: 1.7364\n","Epoch [15/20], Step [114/114], Loss: 2.2449\n","Epoch [16/20], Step [114/114], Loss: 1.1055\n","Epoch [17/20], Step [114/114], Loss: 1.3607\n","Epoch [18/20], Step [114/114], Loss: 1.1881\n","Epoch [19/20], Step [114/114], Loss: 1.2884\n","Epoch [20/20], Step [114/114], Loss: 1.0136"]},{"cell_type":"code","metadata":{"id":"JcgGzqMWwEqt"},"source":["torch.save(net.state_dict(), '/content/drive/My Drive/human_motion/model/net_epoch_40.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"651mKy_Oza3y"},"source":["net = RNN_MODEL(input_size, hidden_size, batch_size, sequence_length, num_layers, num_classes, device).to(device)\n","net.load_state_dict(torch.load('/content/drive/My Drive/human_motion/model/net_epoch_40.ckpt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-W1u3Xb0Uns"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J50liFGsiIM3"},"source":["print(torch.cuda.is_available())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ce9NUR6GkSGJ"},"source":["!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n","!pip3 install torchvision"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-O27JiaokjKp"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiPTAzjDNQ4V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjR29CreX-of"},"source":[""],"execution_count":null,"outputs":[]}]}